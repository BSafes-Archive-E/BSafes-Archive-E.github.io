---
layout: default
title: 1. Introduction
parent: § Experiencing mundane AI futures  
grand_parent: E
nav_order: 10 
---
<style>
.dont-break-out {
  /* These are technically the same, but use both */
  overflow-wrap: break-word;
  word-wrap: break-word;

     -ms-word-break: break-all;
  /* This is the dangerous one in WebKit, as it breaks things wherever */
  word-break: break-all;
  /* Instead use this non-standard one: */
  word-break: break-word;
}

.youtube-container {
    position: relative;
    width: 100%;
    height: 0;
    padding-bottom: 56.25%;
}
.youtube-video {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
}

</style>

<div class="dont-break-out" markdown="1">

1. TOC
{:toc}

## 1. Introduction
AI and data collection have become a central feature of our day-to-day lives, in particular through the rising prevalence of what are oft described as smart products and services within our homes. These include for example, thermostats, streaming services, and personal assistants such as Amazon Alexa. However, the underlying operations relating to AI and the data collection and processing by these networked products and services are predominantly obfuscated, for example when the user’s voice is being recorded to train AI assistants.

While the awareness of our relationships with AI and data infused smart products and services may not be of immediate concern to most users, when this activity is unexpectedly brought to the fore it challenges many of our existing expectations, such as matters to do with personal privacy in our homes. For example, many Roomba vacuum cleaner owners were shocked to learn that the latest versions of the device produced detailed maps of their homes. These were then relayed to the manufacturer to help develop its AI algorithms, but the manufacturer could also potentially share these maps with third parties. While an automatic vacuum cleaner may seem an attractive prospect, a digital device which maps the interior of your home in order to—potentially—sell that map to the highest bidder, is clearly a more complicated proposition. From this example, we can see the tension that home data collection by smart devices places on our expectations of privacy.

Whilst computing power has been increasing over many years within the products with which we share our homes to increase functionality and replace mechanical controls, it is the increasing “networkification” (Pierce & DiSalvo, 2017) of these devices to facilitate new services that is fundamentally changing our relationships with them. To address this challenge, the term Human-Data Interaction (HDI) has been coined to describe this new area for research.

> “HDI places the human at the centre of these data flows, and HDI provides mechanisms which can help the individual and groups of people to interact explicitly with these systems and data.” (Mortier et al, 2016)

While HDI is still a new field, three core design principles for data enabled products and services have been identified: legibility, agency and negotiability.

***Legibility*** recognises that the full extent of our interactions with data flows and data processes are generally opaque. We would distinguish the term from transparency which is primarily related to providing open access to data and algorithms, which does not necessarily make it accessible to non-expert users. Legibility is primarily concerned with ensuring that the use, storage, and sharing of data and associated algorithms are made clear and understandable to users. For example, owners of Vizio smart televisions were unaware that 100 billion data points related to their viewing habits were being collected every day until it was made public in 2016.

***Agency*** relates to how users of data-enabled systems are able to manage their data and who has access to it. Aside from the basic ability to opt-in or opt-out of data collection, agency also relates to how data is stored and used, including the ability to modify data and the inferences that may be ascribed from it. Consider the domestic smart energy meters that are currently being rolled out in the UK. Users have little agency to optimise their tariffs or control who has access to the data which reveals a great deal about the users’ lives and has ultimately reduced their uptake.

***Negotiability*** acknowledges the transactional nature of data collection, particularly in the context of trading functionality. Negotiation seeks to facilitate an ongoing engagement by users in data collection and use so that they can withdraw access completely or in part, and derive value from data collection themselves. For example, if you choose not to connect your Roomba to your Wi-Fi you lose some of the features offered through the mobile app such as remotely scheduled cleanings, customised cleaning features, and any voice control functionality provided by Amazon’s Alexa or Google Assistant. In this instance, the trade-off for loosing this functionality is increased certainty that your data is secure (as it is not leaving your house), however the negotiation is very one-sided. In the Roomba’s case (as is frequently true) the terms equate to ‘give us your data or we do not provide functionality’. Failure to enact HDI may ultimately affects our willingness to adopt and accept networked devices as part of our lives (Lindley et al, 2017), and our willingness can easily be negated when such devices act contrary to our expectations or needs.

The adoption and acceptability of emerging and future technologies directly relates to their potential economic and societal benefits. However, the processes that drive adoption and acceptability are *rare* considerations for research into emerging and future technologies, and are often regarded as someone else’s future work (Lindley et al, 2017). This ‘proximate’ view of the future necessarily occasions what Reeves et al. (2016) call ‘pragmatic projection’, i.e., the translation of grand visions into practical plans for design given what can be built here and now. However, like all plans, pragmatic projections are ‘essentially incomplete’ (Suchman, 1987) and ignore the ‘mundane complexity’ (Redstrom, 2006) that attaches to proximate futures.

> “All designers have to grapple with the unknowability of the future. Objects that are designed here and now will come into use at some future under conditions their creator can neither know nor control … even the most mundane of acts can unravel if expected outcomes are not met.” (Reeves et al, 2016)

The upshot is that the discovery of challenges and barriers to adoption and acceptability typically occur only *after* potentially problematic design patterns have become established, resulting in diminished impact or unintended consequences. By framing this issue as a research challenge, we propose to address future adoption and acceptability from the early stages of the design life cycle using a novel combination of *more-than human centred design, design fiction and breaching experiments* to create **mundane experiential futures** (Coulton et al., 2019). In the subsequent sections we consider the theoretical considerations which scaffold this research, before presenting our research through design approach (Gaver, 2012) to the creation and deployment of one mundane experiential future to consider how the core principles of HDI could be experienced in relation to AI in the home.

***

#### Table of Contents
{: .no_toc}

<ul><li> <a href="/docs/E/Experiencing-mundane-AI-futures-1/">
1. Introduction</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-2/">
2. HDI ≠ HCD</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-3/">
3. Future mundane experiential platform</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-4/">
4. Experiencing a mundane AI future</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-5/">
5. Conclusions</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-6/">
6. References</a></li></ul>
***

</div>
