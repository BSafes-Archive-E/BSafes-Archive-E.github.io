---
layout: default
title: 4. Experiencing a mundane AI future
parent: § Experiencing mundane AI futures 
grand_parent: E
nav_order: 40 
---
<style>
.dont-break-out {
  /* These are technically the same, but use both */
  overflow-wrap: break-word;
  word-wrap: break-word;

     -ms-word-break: break-all;
  /* This is the dangerous one in WebKit, as it breaks things wherever */
  word-break: break-all;
  /* Instead use this non-standard one: */
  word-break: break-word;
}

.youtube-container {
    position: relative;
    width: 100%;
    height: 0;
    padding-bottom: 56.25%;
}
.youtube-video {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
}

</style>

<div class="dont-break-out" markdown="1">

1. TOC
{:toc}

## 4. Experiencing a mundane AI future
This version of the Future Mundane experiential future is split into to two main parts. To begin, the participants seat themselves on the sofa in front of the television screen, as shown in Figure 8. The experience is then introduced using a voice user interface which seeks to gain consent from users to collect, process and store their data (the experience prints out a permission slip using the thermal printer which the audience must sign to proceed). In the second part of the experience a short drama is played based on a profile generated by the system. During this phase various IoT objects in the room begin to contribute to the immersion. For example, the windows become opaque, and the room’s lighting adapts to each scene (the system ‘knows’ the outside weather and picks up a relevant colour gradient). When the lead character in the short drama is outdoors, the fan switches on, matching the wind blowing her hair. The music within the film is chosen dependent on the profile generated by the system, as is the chosen ending. The impact of particular data interactions which affect the drama do not immediately affect the media objects, which means that while each experience was uniquely tailored to the audience, they would not necessarily be able to see why or how. Therefore, these are displayed as captions at the bottom of the screen when data is being collected and subsequently used.

The consent procedure within the experience is designed to prototype the HDI pillars of agency, legibility, and negotiability. The consent involved introducing each sensor in turn, starting with the face recognition system and at each point the audience was asked to indicate their willingness to have their data collected. Whilst this provided legibility, we purposefully did not always provide a choice other than ‘Yes’ or ‘No’. This was intended to highlight the lack of agency and negotiability that many consent systems actually provide. When the audience in the experience said ‘no’ the system would either say this would result in a lesser experience or say that this was a shame as they would miss out on the video, but they could exit through the gift shop. However, during the 2 days the experience ran, none of the 75 people who participated declined consent. This perhaps indicates could be due to the setting in which the experience takes place or perhaps the beguiling nature of voice which may present a problem for future IoT systems in that, if their security is compromised, voice may present nefarious hackers a highly effective means of phishing.

![Figure 8. The audience view from a seated position inside the experience. The screen provides the primary focus for the experience, with additional interactive elements responding to both the short film being played on the screen and user interactions. The images on the left and right also show how smart glass has been used to create a more immersive environment, by providing the ability to control the opacity of the windows.](https://statics.bsafes.com/images/papers/Experiencing-mundane-AI-futures-fig-8.png)

*Figure 8. The audience view from a seated position inside the experience. The screen provides the primary focus for the experience, with additional interactive elements responding to both the short film being played on the screen and user interactions. The images on the left and right also show how smart glass has been used to create a more immersive environment, by providing the ability to control the opacity of the windows.*

The need to ‘design in’ negotiability is also made clear when considering ‘More-Than Human Centred’ theory (Coulton and Lindley, 2019). Most designed things, and the components that make them up, operate familiarly and there is no need to negotiate consent around their use. For example, things such as taps, doorknobs, light switches, and cars have, through a process sometimes referred to as ‘mediation’ (Verbeek, 2015) or ‘domestication’ (Silverstone, 2006), become so very familiar that virtually anyone knows without thinking what to expect from them. Occasionally, technological innovation upsets our familiar relationships with things, and we need help in renegotiating them. For example, car wing mirrors that increase the field of view but make objects appear smaller highlight this to drivers. In some countries these wing mirrors must carry a disclaimer, this begins a kind of dialogue with the user: because the technology has changed, it must increase its negotiability. In the case of connected products in the home, rather like the wing mirror, although outward appearance remains largely similar, the inner workings are often very different. For this reason, our relationships must be renegotiated.

***

#### Table of Contents
{: .no_toc}

<ul><li> <a href="/docs/E/Experiencing-mundane-AI-futures-1/">
1. Introduction</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-2/">
2. HDI ≠ HCD</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-3/">
3. Future mundane experiential platform</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-4/">
4. Experiencing a mundane AI future</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-5/">
5. Conclusions</a></li><li> <a href="/docs/E/Experiencing-mundane-AI-futures-6/">
6. References</a></li></ul>
***

</div>
